{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Lecture 09: Softmax Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[출처](https://www.youtube.com/watch?v=b4Vyma9wPHo&list=PLlMkM4tgfjnJ3I-dbhO9JTw7gNty6o_2m&index=3)"
      ],
      "metadata": {
        "id": "PdsPsKXmJSrj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ReH206zfFgEH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch import nn, optim, cuda\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np.array([1, 0, 0])"
      ],
      "metadata": {
        "id": "Ltyp9MU0lacd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred1 = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred2 = np.array([0.1, 0.3, 0.6])"
      ],
      "metadata": {
        "id": "Vf7x0EuTFojV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(-Y * np.log(Y_pred1)))\n",
        "print(np.sum(-Y * np.log(Y_pred2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUzbOM-69-he",
        "outputId": "ba127de0-d133-4348-cb70-928341deb117"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35667494393873245\n",
            "2.3025850929940455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "nBFL04rzCGtp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = Variable(torch.LongTensor([0]), requires_grad = False)"
      ],
      "metadata": {
        "id": "nhq1a1AsF8Vb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred1 = Variable(torch.Tensor([[2.0, 1.0, 0.1]]))\n",
        "Y_pred2 = Variable(torch.Tensor([[0.5, 2.0, 0.3]]))"
      ],
      "metadata": {
        "id": "3-KYOEjUGXTX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)"
      ],
      "metadata": {
        "id": "WgwNtpk6ilrR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(l1.data)\n",
        "print(l2.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBZum5RxNQFz",
        "outputId": "6c4f2082-dfab-489a-8efc-af7c530ce990"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4170)\n",
            "tensor(1.8406)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "batch_size = 64\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n"
      ],
      "metadata": {
        "id": "OzcJdMvFQVQj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ],
      "metadata": {
        "id": "EBeKfErURZYd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(784, 520)\n",
        "        self.l2 = nn.Linear(520, 320)\n",
        "        self.l3 = nn.Linear(320, 240)\n",
        "        self.l4 = nn.Linear(240, 120)\n",
        "        self.l5 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        return self.l5(x)"
      ],
      "metadata": {
        "id": "BJXZurs2N0i6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFKx4nFCQy4q",
        "outputId": "afb35499-3ae0-466f-86ec-2b60593d3c84"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MNIST Model on cpu\n",
            "============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()"
      ],
      "metadata": {
        "id": "b9urvmvxQwTE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr= 0.01, momentum = 0.5)"
      ],
      "metadata": {
        "id": "yX58v-XTP82r"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "metadata": {
        "id": "6bd2pi4ZQ_23"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss += criterion(output, target).item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)')"
      ],
      "metadata": {
        "id": "3czaQSQCR6PO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "if __name__ == '__main__':\n",
        "    since = time.time()\n",
        "    for epoch in range(1, 10):\n",
        "        epoch_start = time.time()\n",
        "        train(epoch)\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "        test()\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "    m, s = divmod(time.time() - since, 60)\n",
        "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cceDZGLKS6LV",
        "outputId": "52a86546-11d7-476f-8148-da681da2318d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 0.234990\n",
            "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 0.314423\n",
            "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 0.171069\n",
            "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 0.289621\n",
            "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 0.261543\n",
            "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 0.382402\n",
            "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 0.117387\n",
            "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 0.206412\n",
            "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 0.217469\n",
            "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 0.222531\n",
            "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 0.230479\n",
            "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 0.194943\n",
            "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 0.352316\n",
            "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 0.254049\n",
            "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 0.299973\n",
            "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 0.239214\n",
            "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 0.145745\n",
            "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 0.343174\n",
            "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 0.158341\n",
            "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 0.346520\n",
            "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 0.180073\n",
            "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 0.200910\n",
            "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 0.292206\n",
            "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 0.214541\n",
            "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 0.170279\n",
            "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 0.130079\n",
            "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 0.297472\n",
            "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 0.164741\n",
            "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 0.166737\n",
            "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 0.285140\n",
            "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 0.242226\n",
            "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 0.129111\n",
            "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 0.305407\n",
            "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 0.248474\n",
            "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 0.274161\n",
            "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 0.169377\n",
            "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 0.300217\n",
            "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 0.206091\n",
            "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 0.183533\n",
            "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 0.155442\n",
            "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 0.190099\n",
            "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 0.199775\n",
            "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 0.255561\n",
            "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 0.164033\n",
            "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 0.380524\n",
            "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 0.166629\n",
            "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 0.178243\n",
            "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 0.311161\n",
            "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 0.212078\n",
            "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 0.258994\n",
            "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 0.221696\n",
            "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 0.165930\n",
            "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 0.120884\n",
            "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 0.256853\n",
            "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 0.132827\n",
            "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 0.147733\n",
            "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 0.274814\n",
            "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 0.172560\n",
            "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 0.269822\n",
            "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 0.133435\n",
            "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 0.188190\n",
            "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 0.418973\n",
            "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 0.053143\n",
            "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 0.215574\n",
            "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 0.105306\n",
            "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 0.089710\n",
            "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 0.367100\n",
            "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 0.128777\n",
            "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 0.174339\n",
            "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 0.103153\n",
            "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 0.160415\n",
            "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 0.124784\n",
            "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 0.192590\n",
            "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 0.241984\n",
            "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 0.152204\n",
            "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 0.333653\n",
            "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 0.287404\n",
            "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 0.165015\n",
            "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 0.314556\n",
            "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 0.185660\n",
            "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 0.327860\n",
            "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 0.105147\n",
            "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 0.130510\n",
            "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 0.109921\n",
            "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 0.466131\n",
            "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 0.180473\n",
            "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 0.139107\n",
            "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 0.161487\n",
            "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 0.346252\n",
            "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 0.098967\n",
            "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 0.083887\n",
            "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 0.101717\n",
            "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 0.189551\n",
            "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 0.114812\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0031, Accuracy: 9418/10000 (94%)\n",
            "Testing time: 0m 19s\n",
            "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 0.091291\n",
            "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 0.065734\n",
            "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 0.137573\n",
            "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 0.173445\n",
            "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 0.081221\n",
            "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 0.252948\n",
            "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 0.145307\n",
            "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 0.159443\n",
            "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 0.177741\n",
            "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 0.143674\n",
            "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 0.220339\n",
            "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.223384\n",
            "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.177917\n",
            "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.092196\n",
            "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.173575\n",
            "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.209823\n",
            "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.135483\n",
            "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.113485\n",
            "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.141551\n",
            "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.172073\n",
            "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.196277\n",
            "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.144405\n",
            "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.218160\n",
            "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.049020\n",
            "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.231621\n",
            "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.459175\n",
            "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.154163\n",
            "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.205585\n",
            "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.265595\n",
            "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.184476\n",
            "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.219844\n",
            "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.222299\n",
            "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.125374\n",
            "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.185102\n",
            "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.124571\n",
            "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.308504\n",
            "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.126198\n",
            "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.259377\n",
            "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.151574\n",
            "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.316943\n",
            "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.118650\n",
            "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.067139\n",
            "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.102723\n",
            "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.195143\n",
            "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.172916\n",
            "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.113103\n",
            "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.197003\n",
            "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.102401\n",
            "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.059370\n",
            "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.235994\n",
            "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.140353\n",
            "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.112162\n",
            "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.126073\n",
            "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.131005\n",
            "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.147395\n",
            "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.114020\n",
            "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.070750\n",
            "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.076057\n",
            "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.076113\n",
            "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.114930\n",
            "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.249367\n",
            "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.119429\n",
            "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.193070\n",
            "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.290211\n",
            "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.106194\n",
            "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.360030\n",
            "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.132728\n",
            "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.344449\n",
            "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.378588\n",
            "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.125238\n",
            "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.184625\n",
            "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.190460\n",
            "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.081397\n",
            "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.101452\n",
            "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.208603\n",
            "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.036389\n",
            "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.064827\n",
            "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.152609\n",
            "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.048541\n",
            "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.110717\n",
            "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.123921\n",
            "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.052218\n",
            "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.081292\n",
            "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.232657\n",
            "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.188479\n",
            "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.107640\n",
            "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.124047\n",
            "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.121777\n",
            "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.123515\n",
            "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.119875\n",
            "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.091572\n",
            "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.077269\n",
            "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.175333\n",
            "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.091279\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0025, Accuracy: 9541/10000 (95%)\n",
            "Testing time: 0m 19s\n",
            "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.192159\n",
            "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.089951\n",
            "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.165423\n",
            "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.179802\n",
            "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.347079\n",
            "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.109695\n",
            "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.130662\n",
            "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.133014\n",
            "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.154030\n",
            "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.133953\n",
            "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.165037\n",
            "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.029323\n",
            "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.152623\n",
            "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.138811\n",
            "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.046685\n",
            "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.118742\n",
            "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.180050\n",
            "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.075230\n",
            "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.205308\n",
            "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.252015\n",
            "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.335627\n",
            "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.118124\n",
            "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.206698\n",
            "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.145614\n",
            "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.087198\n",
            "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.101545\n",
            "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.104030\n",
            "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.130519\n",
            "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.043802\n",
            "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.044405\n",
            "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.094201\n",
            "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.125282\n",
            "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.311411\n",
            "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.194104\n",
            "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.079092\n",
            "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.128667\n",
            "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.056543\n",
            "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.241006\n",
            "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.104553\n",
            "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.069423\n",
            "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.174027\n",
            "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.103502\n",
            "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.235718\n",
            "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.121954\n",
            "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.130425\n",
            "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.068450\n",
            "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.073718\n",
            "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.112755\n",
            "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.242448\n",
            "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.147959\n",
            "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.166969\n",
            "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.113214\n",
            "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.208668\n",
            "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.339802\n",
            "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.053525\n",
            "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.201593\n",
            "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.164763\n",
            "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.063414\n",
            "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.282533\n",
            "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.074786\n",
            "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.187237\n",
            "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.107354\n",
            "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.057547\n",
            "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.093559\n",
            "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.146163\n",
            "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.081009\n",
            "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.109740\n",
            "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.103073\n",
            "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.081673\n",
            "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.164554\n",
            "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.271084\n",
            "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.095733\n",
            "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.054180\n",
            "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.130651\n",
            "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.140420\n",
            "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.103378\n",
            "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.165310\n",
            "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.111753\n",
            "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.221709\n",
            "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.203498\n",
            "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.127190\n",
            "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.077640\n",
            "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.121046\n",
            "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.184767\n",
            "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.162602\n",
            "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.125320\n",
            "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.157002\n",
            "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.151613\n",
            "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.110064\n",
            "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.198431\n",
            "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.146553\n",
            "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.123285\n",
            "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.332052\n",
            "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.154920\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0022, Accuracy: 9578/10000 (96%)\n",
            "Testing time: 0m 18s\n",
            "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.073057\n",
            "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.033396\n",
            "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.036170\n",
            "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.092623\n",
            "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.090930\n",
            "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.272697\n",
            "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.029261\n",
            "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.078643\n",
            "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.066893\n",
            "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.041569\n",
            "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.140994\n",
            "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.073165\n",
            "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.033182\n",
            "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.075174\n",
            "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.158708\n",
            "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.118904\n",
            "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.048656\n",
            "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.070289\n",
            "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.227218\n",
            "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.172428\n",
            "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.129162\n",
            "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.149789\n",
            "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.139699\n",
            "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.051651\n",
            "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.063875\n",
            "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.059692\n",
            "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.072226\n",
            "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.161994\n",
            "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.223441\n",
            "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.044773\n",
            "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.060208\n",
            "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.046802\n",
            "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.122704\n",
            "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.079934\n",
            "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.125368\n",
            "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.131556\n",
            "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.126689\n",
            "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.074410\n",
            "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.118474\n",
            "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.145335\n",
            "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.039041\n",
            "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.131851\n",
            "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.037235\n",
            "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.202626\n",
            "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.041782\n",
            "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.105321\n",
            "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.125250\n",
            "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.087187\n",
            "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.073499\n",
            "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.055134\n",
            "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.051817\n",
            "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.107807\n",
            "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.150780\n",
            "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.101519\n",
            "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.155912\n",
            "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.179360\n",
            "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.069418\n",
            "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.135500\n",
            "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.030335\n",
            "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.304172\n",
            "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.136702\n",
            "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.172291\n",
            "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.244319\n",
            "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.118086\n",
            "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.128003\n",
            "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.051705\n",
            "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.083987\n",
            "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.028556\n",
            "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.223347\n",
            "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.256399\n",
            "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.144712\n",
            "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.060026\n",
            "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.087530\n",
            "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.067762\n",
            "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.148569\n",
            "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.060085\n",
            "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.051268\n",
            "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.082228\n",
            "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.149858\n",
            "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.025851\n",
            "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.050757\n",
            "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.179158\n",
            "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.064381\n",
            "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.072294\n",
            "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.070621\n",
            "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.150746\n",
            "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.119617\n",
            "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.327317\n",
            "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.144951\n",
            "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.023004\n",
            "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.070837\n",
            "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.093859\n",
            "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.062274\n",
            "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.077463\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0018, Accuracy: 9655/10000 (97%)\n",
            "Testing time: 0m 18s\n",
            "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.099950\n",
            "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.122948\n",
            "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.040413\n",
            "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.105043\n",
            "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.115784\n",
            "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.138231\n",
            "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.043192\n",
            "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.125176\n",
            "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.053612\n",
            "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.114966\n",
            "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.054005\n",
            "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.080412\n",
            "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.068564\n",
            "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.255451\n",
            "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.211571\n",
            "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.087419\n",
            "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.106199\n",
            "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.092528\n",
            "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.026695\n",
            "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.071148\n",
            "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.045521\n",
            "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.046865\n",
            "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.114549\n",
            "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.063199\n",
            "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.033845\n",
            "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.145544\n",
            "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.112455\n",
            "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.167337\n",
            "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.030154\n",
            "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.246193\n",
            "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.138783\n",
            "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.027043\n",
            "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.056113\n",
            "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.138070\n",
            "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.138294\n",
            "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.041802\n",
            "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.040199\n",
            "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.120276\n",
            "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.047489\n",
            "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.060976\n",
            "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.039800\n",
            "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.074445\n",
            "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.082405\n",
            "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.121867\n",
            "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.049191\n",
            "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.147393\n",
            "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.118131\n",
            "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.117579\n",
            "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.206233\n",
            "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.117406\n",
            "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.098759\n",
            "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.176845\n",
            "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.112690\n",
            "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.057674\n",
            "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.102299\n",
            "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.103425\n",
            "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.029002\n",
            "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.090257\n",
            "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.038334\n",
            "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.082798\n",
            "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.128596\n",
            "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.068996\n",
            "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.143586\n",
            "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.091054\n",
            "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.108267\n",
            "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.050211\n",
            "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.073318\n",
            "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.043758\n",
            "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.134009\n",
            "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.019621\n",
            "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.139007\n",
            "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.029028\n",
            "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.051762\n",
            "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.057481\n",
            "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.170529\n",
            "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.077420\n",
            "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.089191\n",
            "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.074842\n",
            "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.113407\n",
            "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.080279\n",
            "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.069820\n",
            "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.079020\n",
            "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.237995\n",
            "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.041128\n",
            "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.048099\n",
            "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.075816\n",
            "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.038360\n",
            "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.035959\n",
            "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.053536\n",
            "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.025583\n",
            "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.158509\n",
            "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.099801\n",
            "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.102294\n",
            "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.119243\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0018, Accuracy: 9672/10000 (97%)\n",
            "Testing time: 0m 18s\n",
            "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.061806\n",
            "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.154491\n",
            "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.129340\n",
            "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.075035\n",
            "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.113810\n",
            "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.084106\n",
            "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.044300\n",
            "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.081489\n",
            "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.082235\n",
            "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.059561\n",
            "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.060558\n",
            "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.138185\n",
            "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.033925\n",
            "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.052843\n",
            "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.107083\n",
            "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.044699\n",
            "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.046662\n",
            "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.082706\n",
            "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.062478\n",
            "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.065891\n",
            "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.011384\n",
            "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.075280\n",
            "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.164285\n",
            "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.036799\n",
            "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.051400\n",
            "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.047145\n",
            "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.087520\n",
            "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.124971\n",
            "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.178263\n",
            "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.045259\n",
            "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.049905\n",
            "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.085459\n",
            "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.087872\n",
            "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.063944\n",
            "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.050290\n",
            "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.064982\n",
            "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.172665\n",
            "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.071538\n",
            "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.038641\n",
            "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.127137\n",
            "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.105244\n",
            "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.021382\n",
            "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.020729\n",
            "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.230812\n",
            "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.133298\n",
            "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.086162\n",
            "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.140515\n",
            "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.041278\n",
            "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.035278\n",
            "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.022437\n",
            "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.078058\n",
            "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.025736\n",
            "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.172066\n",
            "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.042138\n",
            "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.050227\n",
            "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.143096\n",
            "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.020847\n",
            "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.108430\n",
            "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.023199\n",
            "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.090974\n",
            "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.063891\n",
            "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.073333\n",
            "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.062054\n",
            "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.060236\n",
            "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.075253\n",
            "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.072593\n",
            "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.054015\n",
            "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.042221\n",
            "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.025834\n",
            "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.238859\n",
            "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.010516\n",
            "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.110002\n",
            "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.051910\n",
            "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.074076\n",
            "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.102008\n",
            "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.077004\n",
            "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.023605\n",
            "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.059650\n",
            "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.244714\n",
            "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.045402\n",
            "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.150993\n",
            "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.066612\n",
            "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.126856\n",
            "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.117276\n",
            "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.041146\n",
            "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.030353\n",
            "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.056855\n",
            "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.024177\n",
            "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.115925\n",
            "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.035144\n",
            "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.072387\n",
            "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.042338\n",
            "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.061646\n",
            "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.062887\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0016, Accuracy: 9695/10000 (97%)\n",
            "Testing time: 0m 18s\n",
            "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.050032\n",
            "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.070216\n",
            "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.128336\n",
            "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.052707\n",
            "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.158488\n",
            "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.076681\n",
            "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.046120\n",
            "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.046706\n",
            "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.035187\n",
            "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.226224\n",
            "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.167400\n",
            "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.048037\n",
            "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.161787\n",
            "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.102194\n",
            "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.027441\n",
            "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.021378\n",
            "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.125341\n",
            "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.084960\n",
            "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.043173\n",
            "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.121575\n",
            "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.292784\n",
            "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.059536\n",
            "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.062573\n",
            "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.052780\n",
            "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.098920\n",
            "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.044479\n",
            "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.076351\n",
            "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.076246\n",
            "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.022822\n",
            "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.062564\n",
            "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.076827\n",
            "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.033646\n",
            "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.115570\n",
            "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.106018\n",
            "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.045241\n",
            "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.014403\n",
            "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.051289\n",
            "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.106767\n",
            "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.080495\n",
            "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.049963\n",
            "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.015436\n",
            "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.170640\n",
            "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.087430\n",
            "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.019535\n",
            "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.032961\n",
            "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.040178\n",
            "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.042616\n",
            "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.057333\n",
            "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.062647\n",
            "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.021350\n",
            "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.059871\n",
            "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.018661\n",
            "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.105913\n",
            "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.194836\n",
            "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.018923\n",
            "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.054690\n",
            "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.008279\n",
            "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.121587\n",
            "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.194524\n",
            "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.110854\n",
            "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.031794\n",
            "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.008518\n",
            "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.043508\n",
            "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.134515\n",
            "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.069674\n",
            "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.046120\n",
            "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.026827\n",
            "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.126661\n",
            "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.041562\n",
            "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.052489\n",
            "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.016168\n",
            "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.058678\n",
            "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.036168\n",
            "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.071361\n",
            "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.023719\n",
            "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.067745\n",
            "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.050106\n",
            "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.230841\n",
            "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.039959\n",
            "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.031619\n",
            "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.080463\n",
            "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.085221\n",
            "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.043051\n",
            "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.044758\n",
            "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.036844\n",
            "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.043960\n",
            "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.090105\n",
            "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.054402\n",
            "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.058258\n",
            "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.062062\n",
            "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.222896\n",
            "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.098876\n",
            "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.083577\n",
            "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.103828\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0015, Accuracy: 9722/10000 (97%)\n",
            "Testing time: 0m 18s\n",
            "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.083216\n",
            "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.099151\n",
            "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.092554\n",
            "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.052807\n",
            "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.092113\n",
            "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.136844\n",
            "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.025750\n",
            "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.029090\n",
            "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.077215\n",
            "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.021022\n",
            "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.101631\n",
            "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.044439\n",
            "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.060385\n",
            "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.069852\n",
            "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.085026\n",
            "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.017714\n",
            "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.102004\n",
            "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.144410\n",
            "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.030352\n",
            "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.054449\n",
            "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.034771\n",
            "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.035919\n",
            "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.047818\n",
            "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.033941\n",
            "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.068811\n",
            "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.051958\n",
            "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.038425\n",
            "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.090900\n",
            "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.051825\n",
            "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.036814\n",
            "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.062577\n",
            "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.066882\n",
            "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.026843\n",
            "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.094838\n",
            "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.086670\n",
            "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.075585\n",
            "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.010218\n",
            "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.150129\n",
            "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.095035\n",
            "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.064374\n",
            "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.028811\n",
            "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.014694\n",
            "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.046492\n",
            "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.014130\n",
            "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.154075\n",
            "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.079546\n",
            "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.024279\n",
            "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.169771\n",
            "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.041395\n",
            "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.062381\n",
            "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.071576\n",
            "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.046209\n",
            "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.032112\n",
            "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.068265\n",
            "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.021169\n",
            "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.073779\n",
            "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.021443\n",
            "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.029410\n",
            "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.175680\n",
            "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.079911\n",
            "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.100575\n",
            "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.059052\n",
            "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.157052\n",
            "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.035596\n",
            "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.031431\n",
            "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.039515\n",
            "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.079217\n",
            "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.050418\n",
            "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.061718\n",
            "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.058105\n",
            "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.104294\n",
            "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.043409\n",
            "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.205650\n",
            "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.052620\n",
            "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.109643\n",
            "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.024788\n",
            "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.076459\n",
            "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.017785\n",
            "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.037390\n",
            "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.059578\n",
            "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.037509\n",
            "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.035359\n",
            "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.016157\n",
            "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.040271\n",
            "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.101212\n",
            "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.065441\n",
            "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.022844\n",
            "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.040509\n",
            "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.043626\n",
            "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.059966\n",
            "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.141821\n",
            "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.093435\n",
            "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.011612\n",
            "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.049926\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0014, Accuracy: 9730/10000 (97%)\n",
            "Testing time: 0m 18s\n",
            "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.107787\n",
            "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.049579\n",
            "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.020730\n",
            "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.056215\n",
            "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.043308\n",
            "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.026945\n",
            "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.007680\n",
            "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.043142\n",
            "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.065016\n",
            "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.074252\n",
            "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.066667\n",
            "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.036069\n",
            "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.063555\n",
            "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.053413\n",
            "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.023501\n",
            "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.093005\n",
            "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.029772\n",
            "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.002726\n",
            "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.028563\n",
            "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.025072\n",
            "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.028411\n",
            "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.126065\n",
            "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.078784\n",
            "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.090287\n",
            "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.068794\n",
            "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.059952\n",
            "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.040776\n",
            "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.041093\n",
            "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.038371\n",
            "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.030558\n",
            "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.067966\n",
            "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.035849\n",
            "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.082625\n",
            "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.045372\n",
            "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.026517\n",
            "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.019821\n",
            "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.095064\n",
            "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.064912\n",
            "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.040633\n",
            "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.034628\n",
            "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.025828\n",
            "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.053239\n",
            "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.089801\n",
            "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.044756\n",
            "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.026298\n",
            "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.048281\n",
            "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.079222\n",
            "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.013640\n",
            "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.031208\n",
            "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.024757\n",
            "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.035385\n",
            "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.016471\n",
            "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.091202\n",
            "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.016589\n",
            "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.207406\n",
            "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.077106\n",
            "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.088267\n",
            "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.144827\n",
            "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.028919\n",
            "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.071549\n",
            "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.008157\n",
            "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.081046\n",
            "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.074041\n",
            "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.056953\n",
            "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.048943\n",
            "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.062007\n",
            "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.059430\n",
            "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.047183\n",
            "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.230370\n",
            "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.008154\n",
            "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.038134\n",
            "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.033633\n",
            "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.110680\n",
            "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.019492\n",
            "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.033142\n",
            "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.070514\n",
            "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.026943\n",
            "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.044691\n",
            "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.174459\n",
            "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.013689\n",
            "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.031761\n",
            "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.042771\n",
            "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.027708\n",
            "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.041252\n",
            "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.082543\n",
            "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.102004\n",
            "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.062404\n",
            "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.030074\n",
            "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.014653\n",
            "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.047511\n",
            "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.036671\n",
            "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.018260\n",
            "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.035219\n",
            "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.118996\n",
            "Training time: 0m 17s\n",
            "===========================\n",
            "Test set: Average loss: 0.0014, Accuracy: 9726/10000 (97%)\n",
            "Testing time: 0m 18s\n",
            "Total Time: 2m 45s\n",
            "Model was trained on cpu!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vWvSg9cdS6jU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}